{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import networkx as nx\n",
    "import community\n",
    "\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import nltk\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "# import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"Period1.csv\"\n",
    "file2 = \"Period2.csv\"\n",
    "file3 = \"TestData.csv\"\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        data_set = list(reader)\n",
    "        \n",
    "        data_set = [[element[0].split(\" \") for element in data_set],[element[1].split(\" \") for element in data_set],[element[2].split(\" \") for element in data_set]]\n",
    "        del data_set[0][0]\n",
    "        del data_set[1][0]\n",
    "        del data_set[2][0]\n",
    "        return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =readfile(file)\n",
    "data2 = readfile(file2)\n",
    "testdata = readfile(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    features = pd.DataFrame([(data[1][i],data[2][i])for i in range(len(data[0]))])\n",
    "    features.columns = ['From', 'To']\n",
    "                    \n",
    "    year = [i[0] for i in data] \n",
    "\n",
    "    features['From'] = features['From'].apply(lambda x:x[0])\n",
    "    features['To'] = features['To'].apply(lambda x:x[0])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def find_node(node_set1, node_set2):\n",
    "    node_set = pd.concat([node_set1, node_set2], ignore_index=True)\n",
    "    node_set_unique = node_set.loc[node_set.duplicated() == False]\n",
    "    node_set_unique = node_set_unique.reset_index(drop = True)\n",
    "    return node_set_unique\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period1  node: 17028 edge: 154836\n",
      "period2  node: 15565 edge: 98353\n",
      "period_all  node: 23237 edge: 253189\n",
      "period_test  node: 23237 edge: 253189\n"
     ]
    }
   ],
   "source": [
    "features = create_features(data)\n",
    "features2 = create_features(data2)\n",
    "test = create_features(testdata)\n",
    "\n",
    "data1_unique_node = find_node(features['From'],features['To'])\n",
    "data2_unique_node = find_node(features2['From'],features2['To'])\n",
    "all_unique_node = find_node(data1_unique_node, data2_unique_node)\n",
    "\n",
    "#implement networkx\n",
    "data1_edge = [(features['From'][i],features['To'][i])for i in range(len(data[0]))]\n",
    "data2_edge = [(features2['From'][i],features2['To'][i])for i in range(len(data2[0]))]\n",
    "all_edge = data1_edge + data2_edge\n",
    "\n",
    "print('period1 ', 'node:', len(data1_unique_node.values), 'edge:', len(data1_edge))\n",
    "print('period2 ', 'node:', len(data2_unique_node.values), 'edge:', len(data2_edge))\n",
    "print('period_all ', 'node:', len(all_unique_node.values), 'edge:', len(all_edge))\n",
    "print('period_test ', 'node:', len(all_unique_node.values), 'edge:', len(all_edge))\n",
    "# print(data1_edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(nodes, edges):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "#     linked_nodes = [(data['From'][i],data['To'][i])for i in range(len(data))]\n",
    "    G.add_nodes_from(nodes.values)\n",
    "    \n",
    "    G.add_edges_from(edges)\n",
    "    print('node:', G.number_of_nodes(), 'edge:', G.number_of_edges())\n",
    "    \n",
    "    return G\n",
    "\n",
    "def create_digraph(nodes, edges):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "#     linked_nodes = [(data['From'][i],data['To'][i])for i in range(len(data))]\n",
    "    G.add_nodes_from(nodes.values)\n",
    "\n",
    "    G.add_edges_from(edges)\n",
    "    print('node:', G.number_of_nodes(), 'edge:', G.number_of_edges())\n",
    "    \n",
    "    return G\n",
    "\n",
    "def labeling(edges,complement):\n",
    "    label = []\n",
    "    for edge in edges:\n",
    "        label.append(1)\n",
    "        \n",
    "    for edge in list(complement.edges()):\n",
    "        label.append(0)\n",
    "#     for i in range(features.shape[0]):\n",
    "#         a = features['From'][i]\n",
    "#         b = features['To'][i]\n",
    "#         if(a in features2.values or b in features2.values):\n",
    "#             label.append(1)\n",
    "#         else:\n",
    "#             label.append(0)\n",
    "    return label\n",
    "\n",
    "# def draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: 23237 edge: 154698\n",
      "node: 23237 edge: 154836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = create_graph(all_unique_node, data1_edge)\n",
    "graph2 = create_digraph(all_unique_node, data1_edge)\n",
    "nx.is_directed(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: 23237 edge: 252854\n",
      "node: 23237 edge: 253189\n"
     ]
    }
   ],
   "source": [
    "full_graph = create_graph(all_unique_node, all_edge)\n",
    "full_graph2 = create_digraph(all_unique_node, all_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbors(features, G):\n",
    "    nb_common_neighbors = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        nb_common_neighbors.append(len(sorted(nx.common_neighbors(G, a, b)))) # ajoute le nombre de voisins communs\n",
    "    return nb_common_neighbors\n",
    "\n",
    "def Jaccard_coef(features, G):\n",
    "    J = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        pred = nx.jaccard_coefficient(G,[(a,b)])\n",
    "        for u,v,p in pred:\n",
    "            J.append(p)\n",
    "    return J\n",
    "\n",
    "def betweenness_diff(features, G):\n",
    "    btw = nx.betweenness_centrality(G, 50)\n",
    "    btw_diff = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        btw_diff.append(btw[b] - btw[a])\n",
    "    return btw_diff\n",
    "\n",
    "def in_link_diff(features, G2):\n",
    "    diff = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        diff.append(len(G2.in_edges(b)) - len(G2.in_edges(a)))\n",
    "    return diff\n",
    "\n",
    "def is_same_cluster(partition, features):\n",
    "    same_cluster = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        if(partition[a] == partition[b]):\n",
    "            same_cluster.append(1)\n",
    "        else:\n",
    "            same_cluster.append(0)\n",
    "    return same_cluster\n",
    "\n",
    "def adamic_adar(node1,node2, G):\n",
    "    adam = []\n",
    "    adamic_score = 0\n",
    "    a = [n for n in G.neighbors(node1)]\n",
    "    b = [n for n in G.neighbors(node2)]\n",
    "    intersection = list(set(a) & set(b))\n",
    "    \n",
    "    if len(intersection) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for v in intersection:\n",
    "            adamic_score += 1 / math.log(len([nv for nv in G.neighbors(v)]))\n",
    "        return adamic_score\n",
    "    \n",
    "def clustering_coefficient(G, node):\n",
    "    node_degree = G.degree[node]\n",
    "    node_triangle = nx.triangles(G, node)\n",
    "    if node_degree - 1 <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * node_triangle) / (node_degree * (node_degree - 1)) \n",
    "    \n",
    "def preferential_attachment(G, node1, node2): \n",
    "    a = len([n for n in G.neighbors(node1)])\n",
    "    b = len([n for n in G.neighbors(node2)])\n",
    "    return {'pa_mul': a * b, 'pa_add': a + b}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199365 entries, 0 to 199364\n",
      "Data columns (total 2 columns):\n",
      "edge     199365 non-null object\n",
      "label    199365 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#generate model\n",
    "\n",
    "in1_notin2 = data1_unique_node.append(data2_unique_node).drop_duplicates(keep=False)\n",
    "data_shuffle = random.Random(2).sample(list(in1_notin2), 450)\n",
    "sub_graph = graph.subgraph(data_shuffle)\n",
    "# graph_complement = nx.complement(graph)\n",
    "sub_graph_complement = nx.complement(sub_graph)\n",
    "\n",
    "#tagging label\n",
    "train_label = labeling(data2_edge,sub_graph_complement)\n",
    "\n",
    "train_data_edge = data2_edge + list(sub_graph_complement.edges())\n",
    "train_data = pd.DataFrame(data={'edge': train_data_edge, 'label': train_label})\n",
    "train_data = shuffle(train_data, random_state=32).reset_index(drop=True)\n",
    "train_data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 199365\n",
      "10000 199365\n",
      "20000 199365\n",
      "30000 199365\n",
      "40000 199365\n",
      "50000 199365\n",
      "60000 199365\n",
      "70000 199365\n",
      "80000 199365\n",
      "90000 199365\n",
      "100000 199365\n",
      "110000 199365\n",
      "120000 199365\n",
      "130000 199365\n",
      "140000 199365\n",
      "150000 199365\n",
      "160000 199365\n",
      "170000 199365\n",
      "180000 199365\n",
      "190000 199365\n"
     ]
    }
   ],
   "source": [
    "no_common_neighbors = common_neighbors(train_data['edge'].values, full_graph)\n",
    "train_data['No_common_neighbors'] = no_common_neighbors\n",
    "\n",
    "Jaccard = Jaccard_coef(train_data['edge'].values, full_graph)\n",
    "train_data['Jaccard_coef'] = Jaccard\n",
    "\n",
    "# btw_diff = betweenness_diff(train_data['edge'].values, full_graph)\n",
    "# train_data['Betweenness_diff'] = btw_diff\n",
    "\n",
    "# diff = in_link_diff(train_data['edge'].values, full_graph2)\n",
    "# train_data['In_link_diff'] = diff\n",
    "\n",
    "partition = community.best_partition(full_graph)\n",
    "same_cluster_train = is_same_cluster(partition, train_data['edge'].values)\n",
    "train_data['Is_same_cluster'] = same_cluster_train\n",
    "\n",
    "cc_mul, cc_add, pa_mul, pa_add, adamic=[], [],[], [], []\n",
    "\n",
    "# adamic = adamic_adar(features, full_graph)\n",
    "# train_data['adamic'] =pd.Series(adamic, index=train_data.index)\n",
    "\n",
    "# source_cc = clustering_coefficient_mul(full_graph, features)\n",
    "# target_cc = clustering_coefficient_add(full_graph, features)\n",
    "# cc_mul.append(source_cc * target_cc)\n",
    "# cc_add.append(source_cc + target_cc)\n",
    "# train_data['cc_mul'] = cc_mul\n",
    "# train_data['cc_add'] = cc_add\n",
    "\n",
    "# pa_mul, pa_add = preferential_attachment(full_graph, features)\n",
    "\n",
    "\n",
    "for edge_id, edge in enumerate(train_data['edge'].values):\n",
    "    source_id.append(edge[0])\n",
    "    target_id.append(edge[1])\n",
    "    \n",
    "    adamic.append(adamic_adar(edge[0], edge[1], full_graph))\n",
    "    source_cc = clustering_coefficient(full_graph, edge[0])\n",
    "    target_cc = clustering_coefficient(full_graph, edge[1])\n",
    "    cc_mul.append(source_cc * target_cc)\n",
    "    cc_add.append(source_cc + target_cc)\n",
    "    pa = preferential_attachment(full_graph, edge[0], edge[1])\n",
    "    pa_mul.append(pa['pa_mul'])\n",
    "    pa_add.append(pa['pa_add'])\n",
    "    \n",
    "    if edge_id % 10000 == 0:\n",
    "        print(edge_id, len(train_data))\n",
    "        \n",
    "train_data['adamic'] = pd.Series(adamic, index=train_data.index)\n",
    "train_data['cc_mul'] = pd.Series(cc_mul, index=train_data.index)\n",
    "train_data['cc_add'] = pd.Series(cc_add, index=train_data.index)\n",
    "train_data['pa_mul'] = pd.Series(pa_mul, index=train_data.index)\n",
    "train_data['pa_add'] = pd.Series(pa_add, index=train_data.index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "adamic = adamic_adar(features, full_graph)\n",
    "print(len(adamic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save train data\n",
    "train_data_bye = train_data.drop('edge', axis=1)\n",
    "train_data_bye.to_csv(\"train_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# result_list.iloc[0:10000].to_csv('result.csv', sep=',')\n",
    "# features.to_csv('graph_features_training.csv', sep=',')\n",
    "train_data = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = zip(train_data['No_common_neighbors'], train_data['Jaccard_coef'],train_data['Betweenness_diff'],train_data['In_link_diff'], train_data['adamic'], train_data['cc_mul'], train_data['cc_add'],\n",
    "#               train_data['pa_mul'], train_data['pa_add'],train_data['Is_same_cluster'])\n",
    "# feature = [[No_common_neighbors, Jaccard_coef,Betweenness_diff,In_link_diff, adamic, cc_mul, cc_add, pa_mul,pa_add,Is_same_cluster]\n",
    "#            for No_common_neighbors, Jaccard_coef,Betweenness_diff,In_link_diff, adamic, cc_mul, cc_add, pa_mul, pa_add, Is_same_cluster in feature]\n",
    "\n",
    "feature = zip(train_data['No_common_neighbors'], train_data['Jaccard_coef'], train_data['adamic'], train_data['cc_mul'], train_data['cc_add'],\n",
    "              train_data['pa_mul'], train_data['pa_add'],train_data['Is_same_cluster'])\n",
    "feature = [[No_common_neighbors, Jaccard_coef, adamic, cc_mul, cc_add, pa_mul,pa_add,Is_same_cluster]\n",
    "           for No_common_neighbors, Jaccard_coef, adamic, cc_mul, cc_add, pa_mul, pa_add, Is_same_cluster in feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "# SVM\n",
    "\n",
    "# clf = ExtraTreesClassifier(max_features=None, min_samples_leaf=20, n_estimators = 500, n_jobs=3)\n",
    "\n",
    "# clf.fit(feature, train_data['label'].tolist())\n",
    "# # pred = clf.predict(X_test)\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(feature, train_data['label'].tolist())\n",
    "# svm.predict([[0, 0, 0, 0, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(feature, train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "rf = RandomForestClassifier(random_state=0,n_estimators=800)\n",
    "rf = rf.fit(feature, train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = knn.fit(feature, train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=10, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=3,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra trees classifier\n",
    "\n",
    "clf = ExtraTreesClassifier(max_features=None,min_samples_leaf=10,n_estimators=300,n_jobs=3)\n",
    "cv = cross_validation.cross_val_score(clf, feature, train_data['label'].tolist(), cv=5)\n",
    "clf.fit(feature,train_data['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xg boost classifier\n",
    "# 1st tuning\n",
    "\n",
    "gbm = xgb.XGBClassifier(max_depth=6, n_estimators=300, learning_rate=0.01)\n",
    "cv = cross_validation.cross_val_score(gbm, feature, train_data['label'].tolist(), cv=5)\n",
    "print(np.mean(cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-76104063be82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2nd tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# pred = gbm.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 2nd tuning\n",
    "test=np.array(train_data['label'].tolist()) \n",
    "gbm = xgb.XGBClassifier(max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "gbm.fit(feature, test)\n",
    "# pred = gbm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.05, n_estimators=500 ............................\n",
      "[CV] learning_rate=0.05, n_estimators=500 ............................\n",
      "[CV] learning_rate=0.05, n_estimators=500 ............................\n"
     ]
    },
    {
     "ename": "JoblibAttributeError",
     "evalue": "JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10255bf60, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py36/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10255bf60, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py36/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 10, 46, 9, 604128, tzinfo=tzutc()), 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'session': 'E09494868B794B279C3C7591B21BD699', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E09494868B794B279C3C7591B21BD699']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 10, 46, 9, 604128, tzinfo=tzutc()), 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'session': 'E09494868B794B279C3C7591B21BD699', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E09494868B794B279C3C7591B21BD699'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 10, 46, 9, 604128, tzinfo=tzutc()), 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'session': 'E09494868B794B279C3C7591B21BD699', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-30-5790e01bd349>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 10f9ba5f8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x136014930, file \"<ipython-input-30-5790e01bd349>\", line 7>\n        result = <ExecutionResult object at 10f9ba5f8, execution_..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x136014930, file \"<ipython-input-30-5790e01bd349>\", line 7>, result=<ExecutionResult object at 10f9ba5f8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x136014930, file \"<ipython-input-30-5790e01bd349>\", line 7>\n        self.user_global_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nfrom sklearn import preproces...fier, ExtraTreesClassifier)\\nimport xgboost as xgb', 'file = \"Period1.csv\"\\nfile2 = \"Period2.csv\"\\nfile3...       del data_set[2][0]\\n        return data_set', 'data =readfile(file)\\ndata2 = readfile(file2)\\ntestdata = readfile(file3)', 'def create_features(data):\\n    features = pd.Dat...set_index(drop = True)\\n    return node_set_unique', \"features = create_features(data)\\nfeatures2 = cre...ues), 'edge:', len(all_edge))\\n# print(data1_edge)\", 'def create_graph(nodes, edges):\\n    G = nx.Graph...el.append(0)\\n    return label\\n\\n# def draw_graph()', 'graph = create_graph(all_unique_node, data1_edge...l_unique_node, data1_edge)\\nnx.is_directed(graph2)', 'full_graph = create_graph(all_unique_node, all_e...raph2 = create_digraph(all_unique_node, all_edge)', \"def common_neighbors(features, G):\\n    nb_common...)])\\n    return {'pa_mul': a * b, 'pa_add': a + b}\", '#generate model\\n\\nin1_notin2 = data1_unique_node....tate=32).reset_index(drop=True)\\ntrain_data.head()', '\\n\\n# result_list.iloc[0:10000].to_csv(\\'result.csv...p=\\',\\')\\ntrain_data = pd.read_csv(\"train_data.csv\")', \"feature = zip(train_data['No_common_neighbors'],..._add, pa_mul, pa_add, Is_same_cluster in feature]\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = dt.fit(feature, train_data['label'].tolist())\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = rf.fit(feature, train_data['label'].tolist())\", \"\\n# data1_edge = [(features['From'][i],features['...nodes(), 'edge:', network_test.number_of_edges())\", '#testing\\n\\nno_common_neighbors_test = common_neig... = pd.Series(pa_add, index=train_data.index)\\n    ', '\\ntest_feature = [[n, j,b,clus, a, cc_mul, cc_add...redict = rf.predict(test_feature)\\n\\nprint(predict)', \"# output predict\\nrow = [i for i in range(1, 1000...loc[0:10000].to_csv('result_pred_3.csv', sep=',')\", \"# KNN\\nknn = KNeighborsClassifier(n_neighbors=3)\\nknn = knn.fit(feature, train_data['label'].tolist())\", ...], 'Jaccard_coef': <function Jaccard_coef>, 'Jaccard_test': [0.0, 0.0, 0.0, 0.0, 0.0051813471502590676, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015544041450777202, 0.0, 0.0, 0.0, 0.0, ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {7: True, 10:                 edge  label\n0    (3273, 9901003)...9061, 9805170)      1\n4  (102045, 9901128)      1, 26: ExtraTreesClassifier(bootstrap=False, class_weig..., random_state=None, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nfrom sklearn import preproces...fier, ExtraTreesClassifier)\\nimport xgboost as xgb', 'file = \"Period1.csv\"\\nfile2 = \"Period2.csv\"\\nfile3...       del data_set[2][0]\\n        return data_set', 'data =readfile(file)\\ndata2 = readfile(file2)\\ntestdata = readfile(file3)', 'def create_features(data):\\n    features = pd.Dat...set_index(drop = True)\\n    return node_set_unique', \"features = create_features(data)\\nfeatures2 = cre...ues), 'edge:', len(all_edge))\\n# print(data1_edge)\", 'def create_graph(nodes, edges):\\n    G = nx.Graph...el.append(0)\\n    return label\\n\\n# def draw_graph()', 'graph = create_graph(all_unique_node, data1_edge...l_unique_node, data1_edge)\\nnx.is_directed(graph2)', 'full_graph = create_graph(all_unique_node, all_e...raph2 = create_digraph(all_unique_node, all_edge)', \"def common_neighbors(features, G):\\n    nb_common...)])\\n    return {'pa_mul': a * b, 'pa_add': a + b}\", '#generate model\\n\\nin1_notin2 = data1_unique_node....tate=32).reset_index(drop=True)\\ntrain_data.head()', '\\n\\n# result_list.iloc[0:10000].to_csv(\\'result.csv...p=\\',\\')\\ntrain_data = pd.read_csv(\"train_data.csv\")', \"feature = zip(train_data['No_common_neighbors'],..._add, pa_mul, pa_add, Is_same_cluster in feature]\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = dt.fit(feature, train_data['label'].tolist())\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = rf.fit(feature, train_data['label'].tolist())\", \"\\n# data1_edge = [(features['From'][i],features['...nodes(), 'edge:', network_test.number_of_edges())\", '#testing\\n\\nno_common_neighbors_test = common_neig... = pd.Series(pa_add, index=train_data.index)\\n    ', '\\ntest_feature = [[n, j,b,clus, a, cc_mul, cc_add...redict = rf.predict(test_feature)\\n\\nprint(predict)', \"# output predict\\nrow = [i for i in range(1, 1000...loc[0:10000].to_csv('result_pred_3.csv', sep=',')\", \"# KNN\\nknn = KNeighborsClassifier(n_neighbors=3)\\nknn = knn.fit(feature, train_data['label'].tolist())\", ...], 'Jaccard_coef': <function Jaccard_coef>, 'Jaccard_test': [0.0, 0.0, 0.0, 0.0, 0.0051813471502590676, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015544041450777202, 0.0, 0.0, 0.0, 0.0, ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {7: True, 10:                 edge  label\n0    (3273, 9901003)...9061, 9805170)      1\n4  (102045, 9901128)      1, 26: ExtraTreesClassifier(bootstrap=False, class_weig..., random_state=None, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/henrychonghuashiuan/Desktop/course/1062/socialmediamining/homework/Link-Prediction/Link-Prediction/<ipython-input-30-5790e01bd349> in <module>()\n      2 from sklearn.grid_search import GridSearchCV\n      3 parameters = {'n_estimators':[500,1000],\n      4         'learning_rate': [0.05, 0.01, 0.001]}\n      5 \n      6 clf = GridSearchCV( xgb.XGBClassifier(max_depth=4), parameters, n_jobs=4, cv=5, verbose = 10)\n----> 7 clf.fit(feature, train_data['label'].tolist())\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...'2*n_jobs', refit=True, scoring=None, verbose=10), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...])\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...2*n_jobs', refit=True, scoring=None, verbose=10)>\n        X = [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...]\n        y = [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...]\n        self.param_grid = {'learning_rate': [0.05, 0.01, 0.001], 'n_estimators': [500, 1000]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...'2*n_jobs', refit=True, scoring=None, verbose=10), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Mon May 28 18:46:10 2018\nPID: 27803                     Python 3.6.2: /anaconda/envs/py36/bin/python\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], scorer=<function _passthrough_scorer>, train=memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), test=array([    0,     1,     2, ..., 39964, 39968, 39969]), verbose=10, parameters={'learning_rate': 0.05, 'n_estimators': 500}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None,\n       silent=True, subsample=1)>\n        X_train = [[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None)\n    488             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    489             evals = list(zip(evals, eval_names))\n    490         else:\n    491             evals = ()\n    492 \n--> 493         self._features_count = X.shape[1]\n        self._features_count = undefined\n        X.shape = undefined\n    494 \n    495         if sample_weight is not None:\n    496             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    497                                     missing=self.missing, nthread=self.n_jobs)\n\nAttributeError: 'list' object has no attribute 'shape'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py\", line 1675, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py\", line 493, in fit\n    self._features_count = X.shape[1]\nAttributeError: 'list' object has no attribute 'shape'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nAttributeError                                     Mon May 28 18:46:10 2018\nPID: 27803                     Python 3.6.2: /anaconda/envs/py36/bin/python\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], scorer=<function _passthrough_scorer>, train=memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), test=array([    0,     1,     2, ..., 39964, 39968, 39969]), verbose=10, parameters={'learning_rate': 0.05, 'n_estimators': 500}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None,\n       silent=True, subsample=1)>\n        X_train = [[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None)\n    488             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    489             evals = list(zip(evals, eval_names))\n    490         else:\n    491             evals = ()\n    492 \n--> 493         self._features_count = X.shape[1]\n        self._features_count = undefined\n        X.shape = undefined\n    494 \n    495         if sample_weight is not None:\n    496             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    497                                     missing=self.missing, nthread=self.n_jobs)\n\nAttributeError: 'list' object has no attribute 'shape'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nAttributeError                                     Mon May 28 18:46:10 2018\nPID: 27803                     Python 3.6.2: /anaconda/envs/py36/bin/python\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], scorer=<function _passthrough_scorer>, train=memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), test=array([    0,     1,     2, ..., 39964, 39968, 39969]), verbose=10, parameters={'learning_rate': 0.05, 'n_estimators': 500}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None,\n       silent=True, subsample=1)>\n        X_train = [[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None)\n    488             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    489             evals = list(zip(evals, eval_names))\n    490         else:\n    491             evals = ()\n    492 \n--> 493         self._features_count = X.shape[1]\n        self._features_count = undefined\n        X.shape = undefined\n    494 \n    495         if sample_weight is not None:\n    496             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    497                                     missing=self.missing, nthread=self.n_jobs)\n\nAttributeError: 'list' object has no attribute 'shape'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5790e01bd349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m: JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10255bf60, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py36/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10255bf60, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py36/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 10, 46, 9, 604128, tzinfo=tzutc()), 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'session': 'E09494868B794B279C3C7591B21BD699', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E09494868B794B279C3C7591B21BD699']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 10, 46, 9, 604128, tzinfo=tzutc()), 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'session': 'E09494868B794B279C3C7591B21BD699', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E09494868B794B279C3C7591B21BD699'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 10, 46, 9, 604128, tzinfo=tzutc()), 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'session': 'E09494868B794B279C3C7591B21BD699', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7BD31684BF7743668E8FC33CAAEA1568', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#grid search\\nfrom sklearn.grid_search import Gri...0)\\nclf.fit(feature, train_data['label'].tolist())\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-30-5790e01bd349>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 10f9ba5f8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x136014930, file \"<ipython-input-30-5790e01bd349>\", line 7>\n        result = <ExecutionResult object at 10f9ba5f8, execution_..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x136014930, file \"<ipython-input-30-5790e01bd349>\", line 7>, result=<ExecutionResult object at 10f9ba5f8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x136014930, file \"<ipython-input-30-5790e01bd349>\", line 7>\n        self.user_global_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nfrom sklearn import preproces...fier, ExtraTreesClassifier)\\nimport xgboost as xgb', 'file = \"Period1.csv\"\\nfile2 = \"Period2.csv\"\\nfile3...       del data_set[2][0]\\n        return data_set', 'data =readfile(file)\\ndata2 = readfile(file2)\\ntestdata = readfile(file3)', 'def create_features(data):\\n    features = pd.Dat...set_index(drop = True)\\n    return node_set_unique', \"features = create_features(data)\\nfeatures2 = cre...ues), 'edge:', len(all_edge))\\n# print(data1_edge)\", 'def create_graph(nodes, edges):\\n    G = nx.Graph...el.append(0)\\n    return label\\n\\n# def draw_graph()', 'graph = create_graph(all_unique_node, data1_edge...l_unique_node, data1_edge)\\nnx.is_directed(graph2)', 'full_graph = create_graph(all_unique_node, all_e...raph2 = create_digraph(all_unique_node, all_edge)', \"def common_neighbors(features, G):\\n    nb_common...)])\\n    return {'pa_mul': a * b, 'pa_add': a + b}\", '#generate model\\n\\nin1_notin2 = data1_unique_node....tate=32).reset_index(drop=True)\\ntrain_data.head()', '\\n\\n# result_list.iloc[0:10000].to_csv(\\'result.csv...p=\\',\\')\\ntrain_data = pd.read_csv(\"train_data.csv\")', \"feature = zip(train_data['No_common_neighbors'],..._add, pa_mul, pa_add, Is_same_cluster in feature]\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = dt.fit(feature, train_data['label'].tolist())\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = rf.fit(feature, train_data['label'].tolist())\", \"\\n# data1_edge = [(features['From'][i],features['...nodes(), 'edge:', network_test.number_of_edges())\", '#testing\\n\\nno_common_neighbors_test = common_neig... = pd.Series(pa_add, index=train_data.index)\\n    ', '\\ntest_feature = [[n, j,b,clus, a, cc_mul, cc_add...redict = rf.predict(test_feature)\\n\\nprint(predict)', \"# output predict\\nrow = [i for i in range(1, 1000...loc[0:10000].to_csv('result_pred_3.csv', sep=',')\", \"# KNN\\nknn = KNeighborsClassifier(n_neighbors=3)\\nknn = knn.fit(feature, train_data['label'].tolist())\", ...], 'Jaccard_coef': <function Jaccard_coef>, 'Jaccard_test': [0.0, 0.0, 0.0, 0.0, 0.0051813471502590676, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015544041450777202, 0.0, 0.0, 0.0, 0.0, ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {7: True, 10:                 edge  label\n0    (3273, 9901003)...9061, 9805170)      1\n4  (102045, 9901128)      1, 26: ExtraTreesClassifier(bootstrap=False, class_weig..., random_state=None, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nfrom sklearn import preproces...fier, ExtraTreesClassifier)\\nimport xgboost as xgb', 'file = \"Period1.csv\"\\nfile2 = \"Period2.csv\"\\nfile3...       del data_set[2][0]\\n        return data_set', 'data =readfile(file)\\ndata2 = readfile(file2)\\ntestdata = readfile(file3)', 'def create_features(data):\\n    features = pd.Dat...set_index(drop = True)\\n    return node_set_unique', \"features = create_features(data)\\nfeatures2 = cre...ues), 'edge:', len(all_edge))\\n# print(data1_edge)\", 'def create_graph(nodes, edges):\\n    G = nx.Graph...el.append(0)\\n    return label\\n\\n# def draw_graph()', 'graph = create_graph(all_unique_node, data1_edge...l_unique_node, data1_edge)\\nnx.is_directed(graph2)', 'full_graph = create_graph(all_unique_node, all_e...raph2 = create_digraph(all_unique_node, all_edge)', \"def common_neighbors(features, G):\\n    nb_common...)])\\n    return {'pa_mul': a * b, 'pa_add': a + b}\", '#generate model\\n\\nin1_notin2 = data1_unique_node....tate=32).reset_index(drop=True)\\ntrain_data.head()', '\\n\\n# result_list.iloc[0:10000].to_csv(\\'result.csv...p=\\',\\')\\ntrain_data = pd.read_csv(\"train_data.csv\")', \"feature = zip(train_data['No_common_neighbors'],..._add, pa_mul, pa_add, Is_same_cluster in feature]\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = dt.fit(feature, train_data['label'].tolist())\", \"# Random forest\\nrf = RandomForestClassifier(rand...f = rf.fit(feature, train_data['label'].tolist())\", \"\\n# data1_edge = [(features['From'][i],features['...nodes(), 'edge:', network_test.number_of_edges())\", '#testing\\n\\nno_common_neighbors_test = common_neig... = pd.Series(pa_add, index=train_data.index)\\n    ', '\\ntest_feature = [[n, j,b,clus, a, cc_mul, cc_add...redict = rf.predict(test_feature)\\n\\nprint(predict)', \"# output predict\\nrow = [i for i in range(1, 1000...loc[0:10000].to_csv('result_pred_3.csv', sep=',')\", \"# KNN\\nknn = KNeighborsClassifier(n_neighbors=3)\\nknn = knn.fit(feature, train_data['label'].tolist())\", ...], 'Jaccard_coef': <function Jaccard_coef>, 'Jaccard_test': [0.0, 0.0, 0.0, 0.0, 0.0051813471502590676, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015544041450777202, 0.0, 0.0, 0.0, 0.0, ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {7: True, 10:                 edge  label\n0    (3273, 9901003)...9061, 9805170)      1\n4  (102045, 9901128)      1, 26: ExtraTreesClassifier(bootstrap=False, class_weig..., random_state=None, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/henrychonghuashiuan/Desktop/course/1062/socialmediamining/homework/Link-Prediction/Link-Prediction/<ipython-input-30-5790e01bd349> in <module>()\n      2 from sklearn.grid_search import GridSearchCV\n      3 parameters = {'n_estimators':[500,1000],\n      4         'learning_rate': [0.05, 0.01, 0.001]}\n      5 \n      6 clf = GridSearchCV( xgb.XGBClassifier(max_depth=4), parameters, n_jobs=4, cv=5, verbose = 10)\n----> 7 clf.fit(feature, train_data['label'].tolist())\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...'2*n_jobs', refit=True, scoring=None, verbose=10), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...])\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...2*n_jobs', refit=True, scoring=None, verbose=10)>\n        X = [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...]\n        y = [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...]\n        self.param_grid = {'learning_rate': [0.05, 0.01, 0.001], 'n_estimators': [500, 1000]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...'2*n_jobs', refit=True, scoring=None, verbose=10), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Mon May 28 18:46:10 2018\nPID: 27803                     Python 3.6.2: /anaconda/envs/py36/bin/python\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), [[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], <function _passthrough_scorer>, memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), array([    0,     1,     2, ..., 39964, 39968, 39969]), 10, {'learning_rate': 0.05, 'n_estimators': 500}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[16, 0.3555555555555556, 1.0089046452622986e-05, 4.6788013280622165, 0.1368274869419034, 0.7439263686403275, 874, 61, 1], [0, 0.0, -0.0002383330716007457, 0.0, 0.05527065527065527, 0.4763532763532763, 297, 38, 0], [0, 0.0, -5.999028944361097e-06, 0.0, 0.09401709401709403, 0.6153846153846154, 52, 17, 0], [24, 0.1, 0.001078747283654368, 5.5955086352473264, 0.03072858443137183, 0.424239008924808, 10368, 264, 1], [7, 0.0440251572327044, 0.00027791074910076723, 1.6738913200460146, 0.03875397750514949, 0.4389652061062623, 4288, 166, 0], [0, 0.0, 1.0464550381174741e-07, 0.0, 0.0, 0.8571428571428571, 7, 8, 0], [7, 0.05737704918032788, -0.0006935784344775474, 1.7089876101293826, 0.04169453734671126, 0.4496098104793757, 2520, 129, 1], [34, 0.4533333333333333, 5.989390083394379e-05, 8.194344498758069, 0.2105113636363636, 0.9287292649211254, 2860, 109, 1], [1, 0.02083333333333333, 9.882866744725351e-05, 0.3898712452512801, 0.019973009446693658, 0.2998650472334683, 390, 49, 0], [10, 0.11235955056179776, -0.00011206208411647272, 2.473439846600368, 0.03845191179099721, 0.3933695559234817, 2318, 99, 0], [0, 0.0, 2.402503271781093e-05, 0.0, 0.025252525252525256, 0.3207070707070707, 99, 20, 0], [0, 0.0, 6.126296784649418e-05, 0.0, 0.2, 0.9, 24, 10, 0], [0, 0.0, 7.985645526359397e-05, 0.0, 0.05888991484559351, 0.4853801169590643, 361, 38, 0], [4, 0.18181818181818185, 5.657426751033491e-06, 1.2835172975860571, 0.314019314019314, 1.1267066267066266, 168, 26, 1], [0, 0.0, 4.905513088074495e-05, 0.0, 0.0, 0.8666666666666667, 18, 9, 0], [0, 0.0, 0.008223782182949547, 0.0, 0.013888888888888888, 0.375, 96, 22, 0], [11, 0.043307086614173235, 0.0003175158910200924, 2.2845456131275044, 0.04110074617958915, 0.5173643103686977, 7456, 265, 1], [16, 0.14678899082568808, 0.0005645444859845204, 4.421619536705945, 0.05782661782661783, 0.6483205683205683, 2574, 125, 1], [10, 0.09174311926605504, -1.698517934057039e-05, 2.0855853747379074, 0.06525723913242057, 0.5120200554162818, 3498, 119, 1], [0, 0.0, 3.396072938512738e-05, 0.0, 0.06043956043956044, 0.6208791208791209, 56, 18, 0], ...], y=[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...], scorer=<function _passthrough_scorer>, train=memmap([ 39781,  39783,  39784, ..., 199362, 199363, 199364]), test=array([    0,     1,     2, ..., 39964, 39968, 39969]), verbose=10, parameters={'learning_rate': 0.05, 'n_estimators': 500}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None,\n       silent=True, subsample=1)>\n        X_train = [[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/anaconda/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1), X=[[0, 0.0, -8.450356303666994e-05, 0.0, 0.1750140056022409, 1.0084593837535014, 408, 59, 0], [0, 0.0, -0.0005972621308602165, 0.0, 0.014814814814814812, 0.35873015873015873, 70, 17, 0], [0, 0.0, 1.005046670633859e-05, 0.0, 0.0, 0.2584615384615385, 26, 27, 0], [0, 0.0, 1.945723194727168e-05, 0.0, 0.10016784491574407, 0.6666499933306655, 882, 67, 0], [0, 0.0, -1.7376998276008672e-06, 0.0, 0.0, 0.3333333333333333, 3, 4, 0], [0, 0.0, -3.492241048055539e-05, 0.0, 0.09486166007905138, 0.6299642386598908, 161, 30, 0], [0, 0.0, 0.008624207388270065, 0.0, 0.1699346405228758, 0.8431372549019607, 108, 24, 0], [0, 0.0, 2.1160915229129314e-05, 0.0, 0.0925925925925926, 0.7222222222222222, 40, 14, 0], [0, 0.0, 1.4123766898486747e-05, 0.0, 0.0, 0.12727272727272726, 22, 13, 0], [0, 0.0, -3.893388452278774e-05, 0.0, 0.0, 0.6071428571428571, 16, 10, 0], [0, 0.0, -7.665824025260604e-06, 0.0, 0.0, 0.26666666666666666, 6, 7, 0], [0, 0.0, 7.431972914418393e-05, 0.0, 0.09090909090909093, 0.6818181818181819, 55, 16, 0], [0, 0.0, 1.7324255701279278e-05, 0.0, 0.0, 0.13333333333333333, 20, 12, 0], [0, 0.0, -4.073107322620268e-05, 0.0, 0.0, 0.8571428571428571, 14, 9, 0], [0, 0.0, 8.744864453535981e-05, 0.0, 0.06579839913173245, 0.5144485144485145, 189, 34, 0], [0, 0.0, -3.4669024583707116e-06, 0.0, 0.11743740532834357, 0.6856455493183641, 348, 91, 0], [0, 0.0, -6.172491639053032e-06, 0.0, 0.0, 0.3111111111111111, 20, 12, 0], [0, 0.0, 7.303550975799464e-05, 0.0, 0.0, 0.0, 2, 3, 0], [0, 0.0, 0.00024112861463262603, 0.0, 0.04, 0.4166666666666666, 96, 22, 0], [0, 0.0, 1.31938761357419e-05, 0.0, 0.10538179768949, 0.6556776556776557, 182, 27, 0], ...], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None)\n    488             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    489             evals = list(zip(evals, eval_names))\n    490         else:\n    491             evals = ()\n    492 \n--> 493         self._features_count = X.shape[1]\n        self._features_count = undefined\n        X.shape = undefined\n    494 \n    495         if sample_weight is not None:\n    496             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    497                                     missing=self.missing, nthread=self.n_jobs)\n\nAttributeError: 'list' object has no attribute 'shape'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#grid search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {'n_estimators':[500,1000],\n",
    "        'learning_rate': [0.05, 0.01, 0.001]}\n",
    "\n",
    "clf = GridSearchCV( xgb.XGBClassifier(max_depth=4), parameters, n_jobs=4, cv=5, verbose = 10)\n",
    "clf.fit(feature, train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period_test  node: 31491 edge: 262850\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data1_edge = [(features['From'][i],features['To'][i])for i in range(len(data[0]))]\n",
    "# data2_edge = [(features2['From'][i],features2['To'][i])for i in range(len(data2[0]))]\n",
    "# all_edge = data1_edge + data2_edge\n",
    "\n",
    "# step 3 link predict\n",
    "# check test data is in network\n",
    "test_data_unique_node = find_node(test['From'],test['To'])\n",
    "test_data_network = pd.concat([all_unique_node, test_data_unique_node], ignore_index=True)\n",
    "test_data_network = test_data_network.loc[test_data_network.duplicated() == True]\n",
    "test_data_network = test_data_network.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Add test data node & edge in network, implement networkx\n",
    "test_edge = [(test['From'][i],test['To'][i])for i in range(len(test))]\n",
    "network_test = full_graph\n",
    "network_test.add_nodes_from(test_data_unique_node.values)\n",
    "network_test.add_edges_from(test_edge)\n",
    "\n",
    "print('period_test ', 'node:', network_test.number_of_nodes(), 'edge:', network_test.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\n",
    "no_common_neighbors_test = common_neighbors(test_edge, network_test)\n",
    "# test_data_network['No_common_neighbors'] = no_common_neighbors_test\n",
    "\n",
    "Jaccard_test = Jaccard_coef(test_edge, network_test)\n",
    "# test_data_network['Jaccard_coef'] = Jaccard_test\n",
    "\n",
    "# btw_diff_test = betweenness_diff(test_edge, network_test)\n",
    "# # test_data_network['Betweenness_diff'] = btw_diff_test\n",
    "\n",
    "# diff = in_link_diff(test_edge, full_graph2)\n",
    "\n",
    "partition = community.best_partition(network_test)\n",
    "same_cluster_train_test = is_same_cluster(partition, test_edge)\n",
    "# train_data['Is_same_cluster'] = same_cluster_train\n",
    "\n",
    "cc_mul_test, cc_add_test, pa_mul_test, pa_add_test,adamic_test = [],[], [], [],[]\n",
    "source_id, target_id = [],[]\n",
    "for edge_id, edge in enumerate(test_edge):\n",
    "    source_id.append(edge[0])\n",
    "    target_id.append(edge[1])\n",
    "    \n",
    "    adamic_test.append(adamic_adar(edge[0], edge[1], network_test))\n",
    "    source_cc = clustering_coefficient(network_test, edge[0])\n",
    "    target_cc = clustering_coefficient(network_test, edge[1])\n",
    "    cc_mul_test.append(source_cc * target_cc)\n",
    "    cc_add_test.append(source_cc + target_cc)\n",
    "    pa = preferential_attachment(network_test, edge[0], edge[1])\n",
    "    pa_mul_test.append(pa['pa_mul'])\n",
    "    pa_add_test.append(pa['pa_add'])\n",
    "    \n",
    "#     if edge_id % 10000 == 0:\n",
    "#         print(edge_id, len(train_data))\n",
    "        \n",
    "# train_data['adamic'] = pd.Series(adamic, index=train_data.index)\n",
    "# train_data['cc_mul'] = pd.Series(cc_mul, index=train_data.index)\n",
    "# train_data['cc_add'] = pd.Series(cc_add, index=train_data.index)\n",
    "# train_data['pa_mul'] = pd.Series(pa_mul, index=train_data.index)\n",
    "# train_data['pa_add'] = pd.Series(pa_add, index=train_data.index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test_feature = [[n, j,b,inlink,clus, a, cc_mul, cc_add, pa_mul, pa_add] for n, j,b,inlink,clus, a, cc_mul, cc_add, pa_mul,pa_add in \n",
    "#                 zip(no_common_neighbors_test, Jaccard_test,btw_diff_test,diff,same_cluster_train_test, adamic_test, cc_mul_test, cc_add_test,\n",
    "#                     pa_mul_test,pa_add_test)]\n",
    "\n",
    "test_feature = [[n, j,clus, a, cc_mul, cc_add, pa_mul, pa_add] for n, j,clus, a, cc_mul, cc_add, pa_mul,pa_add in \n",
    "                zip(no_common_neighbors_test, Jaccard_test,same_cluster_train_test, adamic_test, cc_mul_test, cc_add_test,\n",
    "                    pa_mul_test,pa_add_test)]\n",
    "\n",
    "# predict = dt.predict(test_feature)\n",
    "predict = rf.predict(test_feature)\n",
    "# predict = knn.predict(test_feature)\n",
    "# predict = clf.predict(test_feature)\n",
    "# predict = svm.predict(test_feature)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output predict\n",
    "row = [i for i in range(1, 10001)]\n",
    "label = predict\n",
    "\n",
    "data = {'target id': row, 'label': label}\n",
    "predict = pd.DataFrame(data=data, columns=['target id', 'label'])\n",
    "predict.to_csv(\"result_pred_rf_n_estimator=800.csv\", index=False)\n",
    "\n",
    "\n",
    "#submission\n",
    "# predict = list(predict) \n",
    "# predict = zip(range(len(predict)), predict)\n",
    "# with open(\"result_pred_3.csv\",\"w\") as pred1:\n",
    "#     csv_out = csv.writer(pred1)\n",
    "#     csv_out.writerow([\"target id\", \"label\"])\n",
    "#     for row in predict:\n",
    "#         csv_out.writerow(row)\n",
    "\n",
    "# with open(\"result_pred_3.csv\", \"r\") as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     data_set = list(reader)\n",
    "# #     data_set = [[element[0].split(\" \") for element in data_set],[element[1].split(\" \") for element in data_set]]  \n",
    "    \n",
    "# result = pd.DataFrame(data_set[1][i] for i in range(1,len(data_set[0])))\n",
    "# result.index = np.arange(1, len(result) + 1)\n",
    "# result.index.name = 'target id'\n",
    "# result.columns = ['label']\n",
    "# result.iloc[0:10000].to_csv('result_pred_3.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features2.to_csv('graph_features_testing.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label = labeling(features, features2)\n",
    "# features['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features.to_csv('graph_features_training_with_label.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "\n",
    "train = pd.read_csv('graph_features_training.csv')\n",
    "del train['Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "X_train = train.as_matrix()\n",
    "\n",
    "y_train = label\n",
    "\n",
    "#testing\n",
    "test = pd.read_csv('graph_features_testing.csv')\n",
    "del test['Unnamed: 0']\n",
    "\n",
    "X_test = test.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93311633282\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98353\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TestData\n",
    "features_test = create_features(testdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "graph_testdata = create_graph(features_test)\n",
    "graph_testdata_2 = create_digraph(features_test)\n",
    "\n",
    "no_common_neighbors_testdata = common_neighbors(features_test, graph_testdata)\n",
    "features_test['No_common_neighbors'] = no_common_neighbors_testdata\n",
    "\n",
    "Jaccard_testdata = Jaccard_coef(features_test, graph_testdata)\n",
    "features_test['Jaccard_coef'] = Jaccard_testdata\n",
    "\n",
    "btw_diff_testdata = betweenness_diff(features_test, graph_testdata)\n",
    "features_test['Betweenness_diff'] = btw_diff_testdata\n",
    "\n",
    "\n",
    "diff3 = in_link_diff(features_test, graph_testdata_2)\n",
    "features_test['In_link_diff'] = diff3\n",
    "\n",
    "partition3 = community.best_partition(graph_testdata)\n",
    "same_cluster_testdata = is_same_cluster(partition3, features_test)\n",
    "features_test['Is_same_cluster'] = same_cluster_testdata\n",
    "\n",
    "# result_list.iloc[0:10000].to_csv('result.csv', sep=',')\n",
    "features_test.to_csv('graph_features_testing_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "testing = pd.read_csv('graph_features_testing_data.csv')\n",
    "del testing['Unnamed: 0']\n",
    "\n",
    "X_test2 = testing.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = gbm.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "predictions = list(pred_test) \n",
    "predictions = zip(range(len(pred_test)), predictions)\n",
    "with open(\"result_pred_2.csv\",\"w\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    csv_out.writerow([\"ID\", \"category\"])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"result_pred_2.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    data_set = list(reader)\n",
    "    data_set = [[element[0].split(\" \") for element in data_set],[element[1].split(\" \") for element in data_set]]  \n",
    "    \n",
    "result = pd.DataFrame(data_set[1][i] for i in range(1,len(data_set[0])))\n",
    "result.index = np.arange(1, len(result) + 1)\n",
    "result.index.name = 'target id'\n",
    "result.columns = ['label']\n",
    "result.iloc[0:10000].to_csv('result_pred_2.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        208165\n",
      "1        111208\n",
      "2        202140\n",
      "3        112113\n",
      "4        108010\n",
      "5        203020\n",
      "6        110022\n",
      "7        111044\n",
      "8        109191\n",
      "9        105097\n",
      "10       203003\n",
      "11       111228\n",
      "12       204066\n",
      "13       102127\n",
      "14       110028\n",
      "15       112180\n",
      "16       204158\n",
      "17       110113\n",
      "18       106149\n",
      "19       105255\n",
      "20         5143\n",
      "21       104041\n",
      "22       202188\n",
      "23       203235\n",
      "24       112126\n",
      "25         1077\n",
      "26       107242\n",
      "27       203208\n",
      "28       109069\n",
      "29       203268\n",
      "         ...   \n",
      "2609    9912018\n",
      "2610    9707133\n",
      "2611    9303017\n",
      "2612    9811089\n",
      "2613     104037\n",
      "2614    9908151\n",
      "2615      12249\n",
      "2616    9901033\n",
      "2617    9711043\n",
      "2618    9701192\n",
      "2619    9508154\n",
      "2620    9506104\n",
      "2621    9504155\n",
      "2622     107123\n",
      "2623    9410010\n",
      "2624     103153\n",
      "2625    9610018\n",
      "2626       9014\n",
      "2627     107147\n",
      "2628    9305125\n",
      "2629    9409110\n",
      "2630    9701028\n",
      "2631    9808010\n",
      "2632     109194\n",
      "2633    9706201\n",
      "2634    9811022\n",
      "2635     110109\n",
      "2636    9608111\n",
      "2637       5275\n",
      "2638    9706139\n",
      "Length: 2639, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_data_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common_neighbors(features, G):\n",
    "    nb_common_neighbors = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        nb_common_neighbors.append(len(sorted(nx.common_neighbors(G, a, b)))) # ajoute le nombre de voisins communs\n",
    "    return nb_common_neighbors\n",
    "\n",
    "def Jaccard_coef(features, G):\n",
    "    J = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        pred = nx.jaccard_coefficient(G,[(a,b)])\n",
    "        for u,v,p in pred:\n",
    "            J.append(p)\n",
    "    return J\n",
    "\n",
    "def betweenness_diff(features, G):\n",
    "    btw = nx.betweenness_centrality(G, 50)\n",
    "    btw_diff = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        btw_diff.append(btw[b] - btw[a])\n",
    "    return btw_diff\n",
    "\n",
    "def in_link_diff(features, G2):\n",
    "    diff = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        diff.append(len(G2.in_edges(b)) - len(G2.in_edges(a)))\n",
    "    return diff\n",
    "\n",
    "def is_same_cluster(partition, features):\n",
    "    same_cluster = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "        a = edge[0]\n",
    "        b = edge[1]\n",
    "        if(partition[a] == partition[b]):\n",
    "            same_cluster.append(1)\n",
    "        else:\n",
    "            same_cluster.append(0)\n",
    "    return same_cluster\n",
    "\n",
    "def adamic_adar(features, G):\n",
    "    adam = []\n",
    "    \n",
    "    for edge_id, edge in enumerate(features):\n",
    "        adamic_score = 0\n",
    "        a = [n for n in G.neighbors(edge[0])]\n",
    "        b = [n for n in G.neighbors(edge[1])]\n",
    "        intersection = list(set(a) & set(b))\n",
    "        if len(intersection) == 0:\n",
    "            adam.append(0)\n",
    "        else:\n",
    "            for v in intersection:\n",
    "                adamic_score += 1 / math.log(len([nv for nv in G.neighbors(v)]))\n",
    "            adam.append(adamic_score)\n",
    "    return adam\n",
    "#     a = [n for n in G.neighbors(node1)]\n",
    "#     b = [n for n in G.neighbors(node2)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def clustering_coefficient_mul(G, node):\n",
    "    cc_mul = []\n",
    "#     cc_add = []\n",
    "    for edge_id, edge in enumerate(node):\n",
    "        a = edge[0]\n",
    "#         b = edge[1]\n",
    "        node_degree = G.degree[a]\n",
    "        node_triangle = nx.triangles(G, a)\n",
    "        if node_degree - 1 <= 0:\n",
    "            cc_mul.append(0)\n",
    "        else:\n",
    "            cc_mul.append((2 * node_triangle) / (node_degree * (node_degree - 1))) \n",
    "    return cc_mul \n",
    "\n",
    "def clustering_coefficient_add(G, node):\n",
    "    cc_add = []\n",
    "#     cc_add = []\n",
    "    for edge_id, edge in enumerate(node):\n",
    "#         a = edge[0]\n",
    "        b = edge[1]\n",
    "        node_degree = G.degree[b]\n",
    "        node_triangle = nx.triangles(G, b)\n",
    "        if node_degree - 1 <= 0:\n",
    "            cc_add.append(0)\n",
    "        else:\n",
    "            cc_add.append((2 * node_triangle) / (node_degree * (node_degree - 1))) \n",
    "    return cc_add\n",
    "    \n",
    "def preferential_attachment(G,features): \n",
    "    pa = {}\n",
    "    pa_mul = []\n",
    "    pa_all = []\n",
    "    for edge_id, edge in enumerate(features):\n",
    "#         a = edge[0]\n",
    "#         b = edge[1]\n",
    "        a = len([n for n in G.neighbors(edge[0])])\n",
    "        b = len([n for n in G.neighbors(edge[1])])\n",
    "        pa.update({'pa_mul': a * b, 'pa_add': a + b})\n",
    "    pa_mul.append(pa['pa_mul'])\n",
    "    pa_add.append(pa['pa_add'])\n",
    "    return pa_mul, pa_add\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
